# FastVLM Server

–û—Ç–¥–µ–ª—å–Ω—ã–π Flask-—Å–µ—Ä–≤–µ—Ä –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –æ–¥–µ–∂–¥—ã —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º FastVLM –º–æ–¥–µ–ª–∏.

## üöÄ –ë—ã—Å—Ç—Ä—ã–π –∑–∞–ø—É—Å–∫

### 1. –°–æ–∑–¥–∞–Ω–∏–µ –≤–∏—Ä—Ç—É–∞–ª—å–Ω–æ–≥–æ –æ–∫—Ä—É–∂–µ–Ω–∏—è
```bash
cd fastvlm-server
python -m venv venv
```

**–ê–∫—Ç–∏–≤–∞—Ü–∏—è –æ–∫—Ä—É–∂–µ–Ω–∏—è:**
- **Windows:** `venv\Scripts\activate`
- **Linux/Mac:** `source venv/bin/activate`

### 2. –£—Å—Ç–∞–Ω–æ–≤–∫–∞ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π
```bash
pip install -r requirements.txt
```

### 3. –ó–∞–ø—É—Å–∫ —Å–µ—Ä–≤–µ—Ä–∞
```bash
python server.py
```

–°–µ—Ä–≤–µ—Ä –∑–∞–ø—É—Å—Ç–∏—Ç—Å—è –Ω–∞ `http://127.0.0.1:3001`

### üöÄ –ê–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã–π –∑–∞–ø—É—Å–∫ (–∏–∑ –∫–æ—Ä–Ω—è –ø—Ä–æ–µ–∫—Ç–∞)
```bash
# –ò–∑ –ø–∞–ø–∫–∏ TgStyle
python start_llm.py
```

## üìã API –≠–Ω–¥–ø–æ–∏–Ω—Ç—ã

### GET `/health`
–ü—Ä–æ–≤–µ—Ä–∫–∞ –∑–¥–æ—Ä–æ–≤—å—è —Å–µ—Ä–≤–µ—Ä–∞

**–û—Ç–≤–µ—Ç:**
```json
{
  "status": "healthy",
  "model_loaded": true,
  "timestamp": 1725623456.789,
  "device": "cuda",
  "torch_version": "2.0.1"
}
```

### POST `/analyze`
–ê–Ω–∞–ª–∏–∑ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –æ–¥–µ–∂–¥—ã

**–ó–∞–ø—Ä–æ—Å:**
```json
{
  "image_base64": "iVBORw0KGgoAAAANSUhEUgAA...",
  "prompt": "–û–ø–∏—à–∏ –æ–¥–µ–∂–¥—É –Ω–∞ —Ñ–æ—Ç–æ"
}
```

**–û—Ç–≤–µ—Ç:**
```json
{
  "success": true,
  "analysis": "–ù–∞ —Ñ–æ—Ç–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∞ —Å–∏–Ω—è—è —Ñ—É—Ç–±–æ–ª–∫–∞ –∏–∑ —Ö–ª–æ–ø–∫–∞ –≤ casual —Å—Ç–∏–ª–µ...",
  "model_used": "llava",
  "device": "cuda"
}
```

### GET `/load`
–ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –Ω–∞–≥—Ä—É–∑–∫–µ —Å–µ—Ä–≤–µ—Ä–∞

**–û—Ç–≤–µ—Ç:**
```json
{
  "cpu_percent": 45.2,
  "memory_percent": 67.8,
  "memory_used_gb": 8.5,
  "memory_total_gb": 16.0,
  "timestamp": 1725623456.789
}
```

### GET `/gpu`
–ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ GPU

**–û—Ç–≤–µ—Ç:**
```json
{
  "gpu_available": true,
  "gpu_name": "NVIDIA GeForce RTX 3080",
  "gpu_memory_allocated_mb": 2048,
  "gpu_memory_reserved_mb": 3072,
  "gpu_memory_total_mb": 10240,
  "device": "cuda"
}
```

### GET `/model`
–ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –∑–∞–≥—Ä—É–∂–µ–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏

**–û—Ç–≤–µ—Ç:**
```json
{
  "loaded": true,
  "model_name": "llava",
  "device": "cuda",
  "context_length": 2048,
  "torch_dtype": "torch.float16",
  "model_path": "/path/to/model"
}
```

## ‚öôÔ∏è –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è

### –ü–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è (.env)
```bash
# Server Settings
FASTVLM_HOST=127.0.0.1
FASTVLM_PORT=3001

# Model Settings
MAX_NEW_TOKENS=256
TEMPERATURE=0.2
DO_SAMPLE=true

# Performance Settings
MAX_IMAGE_SIZE=2048
BATCH_SIZE=1

# Logging Settings
LOG_LEVEL=INFO
LOG_MAX_BYTES=10485760
LOG_BACKUP_COUNT=5
```

### –°—Ç—Ä—É–∫—Ç—É—Ä–∞ —Ñ–∞–π–ª–æ–≤
```
fastvlm-server/
‚îú‚îÄ‚îÄ server.py          # –û—Å–Ω–æ–≤–Ω–æ–π Flask —Å–µ—Ä–≤–µ—Ä
‚îú‚îÄ‚îÄ config.py          # –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è
‚îú‚îÄ‚îÄ requirements.txt   # Python –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏
‚îú‚îÄ‚îÄ .env              # –ü–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è
‚îú‚îÄ‚îÄ logs/             # –õ–æ–≥–∏ —Å–µ—Ä–≤–µ—Ä–∞
‚îú‚îÄ‚îÄ __init__.py       # Python –ø–∞–∫–µ—Ç
‚îî‚îÄ‚îÄ README.md         # –î–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è
```

## üîß –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ API

### –ó–∞–ø—É—Å–∫ —Ç–µ—Å—Ç–æ–≤
```bash
cd fastvlm-server
python test_api.py
```

### –†—É—á–Ω–æ–µ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ
```bash
# Health check
curl http://127.0.0.1:3001/health

# GPU info
curl http://127.0.0.1:3001/gpu

# Load info
curl http://127.0.0.1:3001/load

# Model info
curl http://127.0.0.1:3001/model
```

## üìä –ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥

### –õ–æ–≥–∏
–õ–æ–≥–∏ —Å–µ—Ä–≤–µ—Ä–∞ —Å–æ—Ö—Ä–∞–Ω—è—é—Ç—Å—è –≤ `logs/fastvlm.log`

### –ú–µ—Ç—Ä–∏–∫–∏
- **CPU usage**: `/load`
- **Memory usage**: `/load`
- **GPU memory**: `/gpu`
- **Model status**: `/model`

## üö® –û–±—Ä–∞–±–æ—Ç–∫–∞ –æ—à–∏–±–æ–∫

### –¢–∏–ø–∏—á–Ω—ã–µ –æ—à–∏–±–∫–∏
- **Model not loaded**: –ú–æ–¥–µ–ª—å –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω–∞
- **CUDA out of memory**: –ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ GPU –ø–∞–º—è—Ç–∏
- **Invalid image**: –ù–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ

### –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ
–í—Å–µ –æ—à–∏–±–∫–∏ –ª–æ–≥–∏—Ä—É—é—Ç—Å—è —Å —É—Ä–æ–≤–Ω–µ–º ERROR –≤ `logs/fastvlm.log`

## üîÑ –ü–µ—Ä–µ–∑–∞–ø—É—Å–∫ —Å–µ—Ä–≤–µ—Ä–∞

### Graceful shutdown
–°–µ—Ä–≤–µ—Ä –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ –∑–∞–≤–µ—Ä—à–∞–µ—Ç—Å—è –ø–æ —Å–∏–≥–Ω–∞–ª–∞–º SIGINT/SIGTERM

### –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∞—è –æ—á–∏—Å—Ç–∫–∞
- GPU –ø–∞–º—è—Ç—å –æ—á–∏—â–∞–µ—Ç—Å—è –ø—Ä–∏ –∑–∞–≤–µ—Ä—à–µ–Ω–∏–∏
- –í—Ä–µ–º–µ–Ω–Ω—ã–µ —Ñ–∞–π–ª—ã —É–¥–∞–ª—è—é—Ç—Å—è

## üìà –ü—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å

### –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏
- **GPU acceleration**: –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ CUDA
- **Memory management**: –û—á–∏—Å—Ç–∫–∞ GPU –ø–∞–º—è—Ç–∏
- **Batch processing**: –ü–æ–¥–¥–µ—Ä–∂–∫–∞ –±–∞—Ç—á–µ–≤–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏

### –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏
- **GPU**: –ú–∏–Ω–∏–º—É–º 4GB GPU –ø–∞–º—è—Ç–∏
- **RAM**: –ú–∏–Ω–∏–º—É–º 8GB
- **Disk**: –ú–∏–Ω–∏–º—É–º 10GB –¥–ª—è –º–æ–¥–µ–ª–∏

## üêõ Troubleshooting

### –ú–æ–¥–µ–ª—å –Ω–µ –∑–∞–≥—Ä—É–∂–∞–µ—Ç—Å—è
```bash
# –ü—Ä–æ–≤–µ—Ä–∏—Ç—å –ø—É—Ç—å –∫ –º–æ–¥–µ–ª–∏
python -c "from config import Config; print(Config.MODEL_PATH)"
```

### CUDA –æ—à–∏–±–∫–∞
```bash
# –ü—Ä–æ–≤–µ—Ä–∏—Ç—å CUDA
python -c "import torch; print(torch.cuda.is_available())"
```

### –ü–æ—Ä—Ç –∑–∞–Ω—è—Ç
```bash
# –ò–∑–º–µ–Ω–∏—Ç—å –ø–æ—Ä—Ç –≤ .env
FASTVLM_PORT=3002
```

## üîó –ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è —Å –æ—Å–Ω–æ–≤–Ω—ã–º –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ–º

FastVLM —Å–µ—Ä–≤–µ—Ä —Ä–∞–±–æ—Ç–∞–µ—Ç –∫–∞–∫ –æ—Ç–¥–µ–ª—å–Ω—ã–π –º–∏–∫—Ä–æ—Å–µ—Ä–≤–∏—Å:

```
–û—Å–Ω–æ–≤–Ω–æ–µ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ (Node.js:8443)
    ‚Üì HTTP requests
FastVLM —Å–µ—Ä–≤–µ—Ä (Python:3001)
    ‚Üì FastVLM model
–†–µ–∑—É–ª—å—Ç–∞—Ç—ã –∞–Ω–∞–ª–∏–∑–∞
```

### –ö–ª–∏–µ–Ω—Ç –¥–ª—è Node.js
```javascript
const response = await fetch('http://127.0.0.1:3001/analyze', {
  method: 'POST',
  headers: { 'Content-Type': 'application/json' },
  body: JSON.stringify({
    image_base64: imageData,
    prompt: '–û–ø–∏—à–∏ –æ–¥–µ–∂–¥—É'
  })
});
```

---

*–≠—Ç–æ—Ç —Å–µ—Ä–≤–µ—Ä –æ–±–µ—Å–ø–µ—á–∏–≤–∞–µ—Ç –≤—ã—Å–æ–∫–æ–ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –æ–¥–µ–∂–¥—ã —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º FastVLM –º–æ–¥–µ–ª–∏.*
